{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTJmBrm8+TU8RI5VqEzq9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaaaaamah99/Computer_Vision/blob/main/Week_1/Ultralytics/YOLOv5_Classification_Ultralytics_Med_Data_(Belum_Berhasil).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "m7cDZ0aFevqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a27dDkX3dsJv",
        "outputId": "28ff4498-5272-448f-89c8-f84c12092a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.5 ğŸš€ Python-3.10.12 torch-2.1.2+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.4/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "e6WnsRCYe6y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install YOLOv5 and dependencies\n",
        "!pip install -U torch torchvision\n",
        "!pip install 'git+https://github.com/ultralytics/yolov5.git'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGmfxbuudtHO",
        "outputId": "ee3ccc67-5b55-44e9-a3b7-1c8aa4d072c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting git+https://github.com/ultralytics/yolov5.git\n",
            "  Cloning https://github.com/ultralytics/yolov5.git to /tmp/pip-req-build-mcvkxv7i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/yolov5.git /tmp/pip-req-build-mcvkxv7i\n",
            "  Resolved https://github.com/ultralytics/yolov5.git to commit 050c72cbba9ca24dcff103fca54caf21d7e8b527\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download COCO8 dataset using Roboflow\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8Q4Z4axUIjr8Kb9cHz4O\")\n",
        "project = rf.workspace(\"luca-zedda\").project(\"malaria_syn\")\n",
        "dataset = project.version(4).download(\"yolov5\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzATcfKAfgua",
        "outputId": "42aa6f42-be7f-4b7c-d4c1-78bcfeee4526"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.17)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.18.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.47.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Malaria_syn-4 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6224000/6224000 [02:29<00:00, 41681.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Malaria_syn-4 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24792/24792 [00:54<00:00, 458.14it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-a005eUgqZP",
        "outputId": "0ce86462-bf25-4d95-eee2-afb8dcbe99cb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16383, done.\u001b[K\n",
            "remote: Counting objects: 100% (277/277), done.\u001b[K\n",
            "remote: Compressing objects: 100% (203/203), done.\u001b[K\n",
            "remote: Total 16383 (delta 138), reused 158 (delta 74), pack-reused 16106\u001b[K\n",
            "Receiving objects: 100% (16383/16383), 15.16 MiB | 21.92 MiB/s, done.\n",
            "Resolving deltas: 100% (11175/11175), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd yolov5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f73OgpLsgXHW",
        "outputId": "48f4a8be-2b14-4337-d096-c5b00988a772"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'yolov5'\n",
            "/content/Malaria_syn-4/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4W-dSG6g2aH",
        "outputId": "9e71071c-24ff-41cf-ba14-0bccb002a8c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmarks.py    \u001b[0m\u001b[01;34mdata\u001b[0m/       LICENSE         README.zh-CN.md   tutorial.ipynb\n",
            "CITATION.cff     detect.py   \u001b[01;34mmodels\u001b[0m/         requirements.txt  \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mclassify\u001b[0m/        export.py   pyproject.toml  \u001b[01;34msegment\u001b[0m/          val.py\n",
            "CONTRIBUTING.md  hubconf.py  README.md       train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin master\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qijgHhMShKSx",
        "outputId": "4b7cf472-ac34-41a3-97cb-96a6a139a2bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/ultralytics/yolov5\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbfK8gbLiQid",
        "outputId": "21db5c30-209c-4d87-a2ee-e384e2913c69"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmarks.py    \u001b[0m\u001b[01;34mdata\u001b[0m/       LICENSE         README.zh-CN.md   tutorial.ipynb\n",
            "CITATION.cff     detect.py   \u001b[01;34mmodels\u001b[0m/         requirements.txt  \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mclassify\u001b[0m/        export.py   pyproject.toml  \u001b[01;34msegment\u001b[0m/          val.py\n",
            "CONTRIBUTING.md  hubconf.py  README.md       train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/val.py --img-size 640 --batch-size 32 --data /content/Malaria_syn-4/Malaria_syn-4/data.yaml --weights /path/to/yolov5n.pt --single-cls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNs5PMWSkD4A",
        "outputId": "f9c90dad-abd0-4d47-fe10-da33d48dc520"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/Malaria_syn-4/Malaria_syn-4/data.yaml, weights=['/path/to/yolov5n.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=True, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../../yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ğŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.1.2+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
            "\n",
            "Dataset not found âš ï¸, missing paths ['/content/yolov5/Malaria_syn-4/valid/images']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/val.py\", line 430, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/val.py\", line 401, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/val.py\", line 174, in run\n",
            "    data = check_dataset(data)  # check\n",
            "  File \"/content/yolov5/utils/general.py\", line 534, in check_dataset\n",
            "    raise Exception(\"Dataset not found âŒ\")\n",
            "Exception: Dataset not found âŒ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 ğŸš€ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "    !pip install -q comet_ml\n",
        "    import comet_ml\n",
        "    comet_ml.init()\n",
        "elif logger == 'TensorBoard':\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obaj1ToAeOTJ",
        "outputId": "f706d641-a6be-4105-89a4-31e0a54eac82"
      },
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m599.4/599.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m514.7/514.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img-size 640 --batch-size 16 --epochs 3 --data /content/Malaria_syn-4/Malaria_syn-4/data.yaml --weights yolov5n.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5p0cwWeXk6",
        "outputId": "e2646ef3-2bf4-406f-e124-a8aec9a28c7a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-25 17:09:30.957217: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-25 17:09:30.957278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-25 17:09:30.959595: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=, data=/content/Malaria_syn-4/Malaria_syn-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.1.2+cu121 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/aaaaaamah99/yolov5/3637e153ef994f72911d80c54522cc13\u001b[0m\n",
            "\n",
            "\n",
            "Dataset not found âš ï¸, missing paths ['/content/Malaria_syn-4/yolov5/Malaria_syn-4/valid/images']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Malaria_syn-4/yolov5/train.py\", line 836, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/Malaria_syn-4/yolov5/train.py\", line 616, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/Malaria_syn-4/yolov5/train.py\", line 147, in train\n",
            "    loggers = Loggers(\n",
            "  File \"/content/Malaria_syn-4/yolov5/utils/loggers/__init__.py\", line 146, in __init__\n",
            "    self.comet_logger = CometLogger(self.opt, self.hyp)\n",
            "  File \"/content/Malaria_syn-4/yolov5/utils/loggers/comet/__init__.py\", line 97, in __init__\n",
            "    self.data_dict = self.check_dataset(self.opt.data)\n",
            "  File \"/content/Malaria_syn-4/yolov5/utils/loggers/comet/__init__.py\", line 247, in check_dataset\n",
            "    return check_dataset(data_file)\n",
            "  File \"/content/Malaria_syn-4/yolov5/utils/general.py\", line 534, in check_dataset\n",
            "    raise Exception(\"Dataset not found âŒ\")\n",
            "Exception: Dataset not found âŒ\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/aaaaaamah99/yolov5/3637e153ef994f72911d80c54522cc13\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 1 (103 bytes)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolov5n.pt format=torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOhcOefNei-P",
        "outputId": "ed522cd0-66bb-48ce-ff0a-56027332ea5e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP ğŸ’¡ Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov5nu.pt to 'yolov5nu.pt'...\n",
            "100% 5.27M/5.27M [00:00<00:00, 68.0MB/s]\n",
            "Ultralytics YOLOv8.1.5 ğŸš€ Python-3.10.12 torch-2.1.2+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv5n summary (fused): 193 layers, 2649200 parameters, 0 gradients, 7.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov5nu.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.1.2+cu121...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 3.7s, saved as 'yolov5nu.torchscript' (10.6 MB)\n",
            "\n",
            "Export complete (5.6s)\n",
            "Results saved to \u001b[1m/content/Malaria_syn-4/yolov5\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov5nu.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov5nu.torchscript imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov5n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov5n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "results = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bHbh1mokeo33",
        "outputId": "e4ad2d9f-7ccf-40c6-826d-89c2bd9a147e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP ğŸ’¡ Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Ultralytics YOLOv8.1.5 ğŸš€ Python-3.10.12 torch-2.1.2+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5n.pt, data=coco128.yaml, epochs=3, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\n",
            "Dataset 'coco128.yaml' images not found âš ï¸, missing path '/content/datasets/coco128/images/train2017'\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to '/content/datasets/coco128.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.66M/6.66M [00:00<00:00, 62.2MB/s]\n",
            "Unzipping /content/datasets/coco128.zip to /content/datasets/coco128...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 263/263 [00:00<00:00, 1631.52file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success âœ… (1.4s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 16.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
            " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
            " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 24        [17, 20, 23]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLOv5n summary: 262 layers, 2654816 parameters, 2654800 gradients, 7.8 GFLOPs\n",
            "\n",
            "Transferred 427/427 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/aaaaaamah99/general/334dce10f71942d2a8cc684af572f410\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 0 images, 0 backgrounds, 128 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 482.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000009.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000009.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000025.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000025.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000030.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000030.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000034.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000034.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000036.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000036.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000042.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000042.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000049.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000049.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000061.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000061.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000064.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000064.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000071.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000071.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000072.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000072.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000073.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000073.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000074.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000074.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000077.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000077.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000078.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000078.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000081.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000081.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000086.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000086.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000089.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000089.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000092.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000092.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000094.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000094.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000109.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000109.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000110.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000110.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000113.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000113.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000127.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000127.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000133.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000133.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000136.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000136.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000138.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000138.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000142.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000142.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000143.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000143.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000144.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000144.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000149.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000149.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000151.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000151.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000154.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000154.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000164.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000164.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000165.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000165.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000192.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000192.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000194.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000194.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000196.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000196.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000201.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000201.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000208.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000208.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000241.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000241.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000247.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000247.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000250.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000250.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000257.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000257.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000260.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000260.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000263.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000263.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000283.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000283.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000294.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000294.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000307.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000307.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000308.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000308.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000309.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000309.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000312.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000312.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000315.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000315.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000321.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000321.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000322.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000322.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000326.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000326.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000328.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000328.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000332.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000332.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000338.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000338.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000349.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000349.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000357.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000357.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000359.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000359.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000360.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000360.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000368.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000368.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000370.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000370.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000382.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000382.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000384.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000384.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000387.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000387.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000389.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000389.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000394.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000394.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000395.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000395.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000397.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000397.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000400.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000400.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000404.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000404.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000415.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000415.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000419.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000419.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000428.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000428.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000431.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000431.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000436.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000436.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000438.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000438.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000443.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000443.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000446.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000446.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000450.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000450.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000459.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000459.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000471.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000471.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000472.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000472.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000474.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000474.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000486.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000486.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000488.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000488.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000490.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000490.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000491.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000491.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000502.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000502.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000508.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000508.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000510.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000510.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000514.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000514.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000520.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000520.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000529.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000529.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000531.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000531.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000532.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000532.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000536.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000536.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000540.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000540.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000542.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000542.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000544.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000544.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000560.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000560.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000562.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000562.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000564.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000564.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000569.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000569.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000572.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000572.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000575.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000575.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000581.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000581.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000584.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000584.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000589.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000589.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000590.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000590.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000595.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000595.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000597.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000597.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000599.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000599.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000605.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000605.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000612.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000612.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000620.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000620.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000623.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000623.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000625.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000625.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000626.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000626.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000629.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000629.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000634.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000634.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000636.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000636.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000641.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000641.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000643.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000643.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/coco128/images/train2017/000000000650.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/coco128/images/train2017/000000000650.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ No labels found in /content/datasets/coco128/labels/train2017.cache. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "WARNING âš ï¸ No images found in /content/datasets/coco128/labels/train2017.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-112656b3cda8>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coco128.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# evaluate model performance on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://ultralytics.com/images/bus.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# predict on an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;31m# NOTE: When training DOTA dataset, double batch size could get OOM cause some images got more than 2000 objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \"\"\"\n\u001b[1;32m     42\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;34m\"\"\"Build YOLO Dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     return YOLODataset(\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Check if the dataset is all boxes or all segments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bboxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"segments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mlen_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen_boxes\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen_segments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             LOGGER.warning(\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q52-wBnPmnuP",
        "outputId": "cc2c0d25-e15c-42c2-c5a8-fb6e8b2667cb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.30M/5.30M [00:00<00:00, 63.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.5 ğŸš€ Python-3.10.12 torch-2.1.2+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=mnist160, epochs=3, time=None, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\n",
            "Dataset not found âš ï¸, missing path /content/datasets/mnist160, attempting download...\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/mnist160.zip to '/content/datasets/mnist160.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70.0k/70.0k [00:00<00:00, 5.21MB/s]\n",
            "Unzipping /content/datasets/mnist160.zip to /content/datasets/mnist160...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<00:00, 5931.81file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success âœ… (0.6s), saved to \u001b[1m/content/datasets/mnist160\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist160/train... found 80 images in 10 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist160/test... found 80 images in 10 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
            "YOLOv8n-cls summary: 99 layers, 1451098 parameters, 1451098 gradients, 3.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/mnist160/train... 80 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 11944.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/mnist160/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/mnist160/test... 80 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 24800.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/mnist160/test.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3         0G      2.196         16        224:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:05,  1.43s/it]Exception in thread Thread-39 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n",
            "        1/3         0G      2.246         16        224:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:03,  1.26s/it]Exception in thread Thread-40 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n",
            "        1/3         0G      2.289         16        224:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:03<00:02,  1.15s/it]Exception in thread Thread-41 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n",
            "        1/3         0G      2.308         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.09s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.112      0.575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3         0G      2.337         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.00s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.125      0.575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3         0G       2.28         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.05s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.125      0.575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.5 ğŸš€ Python-3.10.12 torch-2.1.2+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n",
            "WARNING âš ï¸ Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist160/train... found 80 images in 10 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist160/test... found 80 images in 10 classes âœ… \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.84it/s]Exception in thread Thread-43 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    Exception in thread self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "Thread-42 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "        if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "self.run()\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n",
            "               classes   top1_acc   top5_acc:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.45it/s]Exception in thread Thread-44 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    Exception in thread # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)Thread-45 (plot_images)\n",
            "TypeError:\n",
            ": Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "function takes at most 14 arguments (17 given)\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.64it/s]\n",
            "Exception in thread Thread-46 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n",
            "Exception in thread Thread-47 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/plotting.py\", line 777, in plot_images\n",
            "    annotator.im.save(fname)  # save\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2431, in save\n",
            "    if params.get(\"append\", False):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 824, in _save\n",
            "    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 520, in _save\n",
            "    :param im: Image object.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 531, in _encode_tile\n",
            "    # It would be great if we could have the encoder specify what it needs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 438, in _getencoder\n",
            "    return _E(self.scale, self.offset + other)\n",
            "TypeError: function takes at most 14 arguments (17 given)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.125      0.575\n",
            "Speed: 0.0ms preprocess, 14.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/F1_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/P_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/R_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/PR_curve.png for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/labels.jpg for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/labels_correlogram.jpg for uploading.\n",
            "Please double-check the file path and permissions\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Error logging confusion matrix; ignoring\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/aaaaaamah99/general/334dce10f71942d2a8cc684af572f410\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top1 [8] : (0.1125, 0.125)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top5 [8] : (0.574999988079071, 0.575)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 3.37\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 1451098\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 14.073\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [6]            : (2.27953, 2.33715)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/loss [6]              : (2.29502, 2.29791)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/coco128.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov5n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 50\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (2.85 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 476k/476k [00:00<00:00, 12.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1 /content/Malaria_syn-4/yolov5/bus.jpg: 224x224 9 0.19, 0 0.12, 6 0.12, 8 0.12, 5 0.10, 18.3ms\n",
            "Speed: 14.1ms preprocess, 18.3ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
              " obb: None\n",
              " orig_img: array([[[122, 148, 172],\n",
              "         [120, 146, 170],\n",
              "         [125, 153, 177],\n",
              "         ...,\n",
              "         [157, 170, 184],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        [[127, 153, 177],\n",
              "         [124, 150, 174],\n",
              "         [127, 155, 179],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [159, 172, 186],\n",
              "         [159, 172, 186]],\n",
              " \n",
              "        [[128, 154, 178],\n",
              "         [126, 152, 176],\n",
              "         [126, 154, 178],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[185, 185, 191],\n",
              "         [182, 182, 188],\n",
              "         [179, 179, 185],\n",
              "         ...,\n",
              "         [114, 107, 112],\n",
              "         [115, 105, 111],\n",
              "         [116, 106, 112]],\n",
              " \n",
              "        [[157, 157, 163],\n",
              "         [180, 180, 186],\n",
              "         [185, 186, 190],\n",
              "         ...,\n",
              "         [107,  97, 103],\n",
              "         [102,  92,  98],\n",
              "         [108,  98, 104]],\n",
              " \n",
              "        [[112, 112, 118],\n",
              "         [160, 160, 166],\n",
              "         [169, 170, 174],\n",
              "         ...,\n",
              "         [ 99,  89,  95],\n",
              "         [ 96,  86,  92],\n",
              "         [102,  92,  98]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/Malaria_syn-4/yolov5/bus.jpg'\n",
              " probs: ultralytics.engine.results.Probs object\n",
              " save_dir: None\n",
              " speed: {'preprocess': 14.106035232543945, 'inference': 18.349885940551758, 'postprocess': 0.06604194641113281}]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xkkGlf5lm2px"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}